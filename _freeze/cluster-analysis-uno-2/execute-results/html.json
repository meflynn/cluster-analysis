{
  "hash": "2abc9fb12aafdc85ac0cc4c7195f032c",
  "result": {
    "markdown": "---\ntitle: \"Exploratory Cluster Analysis for Josie Schafer: Part 2\"\nauthor: \"Michael Flynn, Prior Analytics, LLC.\"\nfontsize: \"11\"\nformat: \n  html: default\n  pdf: default\npdf-engine: pdflatex\ncsl: \"CSL/apsa.csl\"\nbibliography: references.bib\n---\n\n\n\n\n# Goals\n\n1.  Focus on developing and refining the clustering procedure.\n2.  Look at making the distribution of MSAs across clusters more even.\n3.  Focus on trying to develop more coherence with respect to demographics, higher education, and hospital elements of the cluster procedures. That is, make sure clusters make more sense.\n\n# Notes\n\n1.  Previously focused on hierarchical clustering\n2.  Look at K-means clustering more. This pre-specifies the number of clusters in the data.\n3.  Also possible to look at principal components analysis or factor analysis.\n4.  Revisit the distance calculation.\n\n-   Hierarchical clustering may still make sense if we're calculating the distance using alternative methods.\n-   Euclidean distance will calculate distance on the basis of similarities across levels of inputs. Euclidean is the default, but other algorithms may offer better results.\n-   Correlation based distance calculations may make more sense as we're interested in similarities along the basis of the input measures.\n-   Be aware that we're looking at the `dist()` function distance calculation and then the algorithm for calculating the clusters in `hclust()`. The former handles the distance calculation and the latter handles the breakdown into different clusters.\n-   We want to continue rescaling the measures so that certain large values from spending variables don't overwhelm the influence of other variables not on such large scales.\n\n5.  I'm going to try another rescaling procedure, but there are some definite outliers, so reverting to the 0-1 scaling may prove to be a better option still. But some spending-based measures produce large outliers and this may help to differentiate some MSAs.\n\n# Data Cleaning\n\nJust like last time we read in the data and clean it and rescale the variables. Again, rescaling is done using z-score methods this time rather than the proportion-based measure. This seems to help produce more revenly distributed clusters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read in data and select relevant variables for clusters. \n# Focus is on demographic and anchor institution variables.\n\n# Read in raw data file\ndata <- readxl::read_xlsx(here(\"data/anchor regions analysis.xlsx\"))\n\n# List of variables to include in clustering\nvarlist <- c(\"totpop_19\",  # Total pop\n             \"popchange\",  # pop change\n             \"medage\",     # Median age\n             \"labfor\",     # percent population in labor force\n             \"pov\",       # percent population living in poverty\n             \"poc\",       # people of color as percent of pop\n             \"highed\",     # Percent population with at least bachelor's \n             \"forborn\",    # Percent population foreign born\n             \"net_mig\",    # Net domestic migration\n             \"highered_emp_qcew\", \n             \"highered_estab_qcew\",\n             \"hospital_emp_qcew\", \n             \"hospital_estab_qcew\",\n             \"inst_ipeds_enrollment_all\", \n             \"inst_ipeds_doctoralunihighrese\", \n             \"inst_ipeds_pellawards\",\n             \"inst_hosp_ahacommunityhospitals\",\n             \"inst_hosp_ahabeds\",\n             \"inst_hosp_nihresearchfunding\")\n\n# Rescale the variables from 0-1\ndata.clean <- data |>\n  mutate(across(all_of(varlist), # Variables to scale\n                ~scale(.x),                                          # Scale relative to max\n                .names = \"{col}_rescaled\")) |>                             # Add \"max\" suffix\n  dplyr::select(MSA, ends_with(\"_rescaled\")) |>                            # select chosen variables\n  column_to_rownames(\"MSA\")\n```\n:::\n\n\n# Clustering Methods\n\n## Hierarchical Clustering Procedure\n\nRescaling to z scores rather than scaling relative to the maximum of the category produces more evenly distributed clusters, all else being equal.\n\nI'm keeping the same number of clusters (i.e. 8 clusters with sizes ranging from 5--40, increasing in increments of 5).\n\n### Euclidean Distance Method\n\nThis first chunk replices the Euclidean distance approach from the first phase.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndistance <- dist(data.clean) # calculate Euclidean distance between obs\n\nhc.tree <- hclust(distance, method = \"complete\") # Create cluster groupings based on distance\n\n\n# List of distances to use in generating clusters\ncluster.size.list <- list(\"5\" = 5, \n                          \"10\" = 10,\n                          \"15\" = 15,\n                          \"20\" = 20, \n                          \"25\" = 25, \n                          \"30\" = 30,\n                          \"35\" = 35,\n                          \"40\" = 40)\n\ncluster.ids <- map(\n  .x = seq_along(cluster.size.list),\n  .f = ~ cutree(hc.tree, k = cluster.size.list[[.x]])\n                   ) |> \n  bind_cols() \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...4`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n```\n:::\n\n```{.r .cell-code}\nnames(cluster.ids) <- c(\"cluster_5\", \"cluster_10\", \"cluster_15\", \"cluster_20\", \"cluster_25\", \"cluster_30\", \"cluster_35\", \"cluster_40\")\n\ndata.out.euc <- data |> \n  bind_cols(cluster.ids) |> \n  dplyr::select(starts_with(\"cluster\"), Name, State, MSA, varlist)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\nℹ Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %>% select(varlist)\n\n  # Now:\n  data %>% select(all_of(varlist))\n\nSee <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n```\n:::\n\n```{.r .cell-code}\nnames(data.out.euc) <- c(\"Cluster 5\",\n                     \"Cluster 10\",\n                     \"Cluster 15\",\n                     \"Cluster 20\",\n                     \"Cluster 25\",\n                     \"Cluster 30\",\n                     \"Cluster 35\",\n                     \"Cluster 40\",\n                     \"Name\",\n                     \"State\",\n                     \"MSA\",\n                     \"Total Population (2019)\",\n                     \"Population Change\",\n                     \"Median Age\",\n                     \"% Population in Labor Force\",\n                     \"% Population in Poverty\",\n                     \"% Population People of Color\",\n                     \"$% Population with Bachelor's Degree\",\n                     \"% Population Foreign Born\",\n                     \"Net Domestic Migration\",\n                     \"Higher Education Employment\",\n                     \"Higher Education Establishments\",\n                     \"Hospital Employment\",\n                     \"Hospital Establishments\",\n                     \"Higher Education Enrollment\",\n                     \"High Research Doctoral Degree Institutions\",\n                     \"Total Pell Grant Amounts Awarded\",\n                     \"Hospitals/Community Hospitals\",\n                     \"Hospital Beds\",\n                     \"NIH Research Funding\")\n\nwrite_csv(data.out.euc,\n          here::here(\"data/raw-data-with-cluster-ids-euclidean.csv\"))\n```\n:::\n\n\n#### Visualization for Euclidean Distance Method\n\nThis part includes some sample figures to show what the distribution of some of the inputs looks like across clusters.\n\nOne important take away across all methods is that the more clusters we get the more likely we are to have similar average levels of a variable across clusters.\n\nFor the Euclidean distance calculation method, we end up with several very small clusters as we increase the total number of clusters. So as we move to more than 15-20 clusters we start seeing lots of clusters with only a few, or even a single, member.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.long <- data.out.euc |> \n  pivot_longer(cols = starts_with(\"Cluster\"),\n               names_to = \"Cluster Size\",\n               values_to = \"Cluster ID\") |> \n  mutate(`Cluster Size` = factor(`Cluster Size`, \n                                 levels = c(\"Cluster 5\", \n                                            \"Cluster 10\", \n                                            \"Cluster 15\", \n                                            \"Cluster 20\", \n                                            \"Cluster 25\", \n                                            \"Cluster 30\", \n                                            \"Cluster 35\", \n                                            \"Cluster 40\")))\n\n\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `% Population Foreign Born`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Euclidean Distance Method\",\n       subtitle = \"% Foreign Born\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `Higher Education Employment`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Euclidean Distance Method\",\n       subtitle = \"Higher Education Employment\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `% Population People of Color`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Euclidean Distance Method\",\n       subtitle = \"% Population People of Color\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-1-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `Hospital Establishments`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Euclidean Distance Method\",\n       subtitle = \"Hospital Establishments\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-1-4.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `NIH Research Funding`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Euclidean Distance Method\",\n       subtitle = \"NIH Research Funding\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-1-5.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `Total Pell Grant Amounts Awarded`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Euclidean Distance Method\",\n       subtitle = \"Total Pell Grant Amounts Awarded\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-1-6.png){width=672}\n:::\n:::\n\n\n### Correlation Method\n\nThis time I calculate distance according to the correlation method. Resources indicate that the correlation method can be better for matching similarities across dimensions, whereas Euclidean distance is going to be better at matching on the basis of volume/spending levels, regardless of similarities across particular dimensions/variables [@JamesWittenHastieTibshirani2021]. If the goal is to generate clusters that are more readily identifiable on the basis of the three core dimensions, this is more likely to do that.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndistance.matrix <- as.matrix(data.clean) # convert to matrix\n\ndistance <- as.dist(1 - cor(t(distance.matrix))) # calculate correlation-based\n\nhc.tree <- hclust(distance, method = \"complete\") # Create cluster groupings based on distance\n\n\n# List of distances to use in generating clusters\ncluster.size.list <- list(\"5\" = 5, \n                          \"10\" = 10,\n                          \"15\" = 15,\n                          \"20\" = 20, \n                          \"25\" = 25, \n                          \"30\" = 30,\n                          \"35\" = 35,\n                          \"40\" = 40)\n\ncluster.ids <- map(\n  .x = seq_along(cluster.size.list),\n  .f = ~ cutree(hc.tree, k = cluster.size.list[[.x]])\n                   ) |> \n  bind_cols() \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...4`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n```\n:::\n\n```{.r .cell-code}\nnames(cluster.ids) <- c(\"cluster_5\", \"cluster_10\", \"cluster_15\", \"cluster_20\", \"cluster_25\", \"cluster_30\", \"cluster_35\", \"cluster_40\")\n\ndata.out.cor <- data |> \n  bind_cols(cluster.ids) |> \n  dplyr::select(starts_with(\"cluster\"), Name, State, MSA, varlist)\n\nnames(data.out.cor) <- c(\"Cluster 5\",\n                     \"Cluster 10\",\n                     \"Cluster 15\",\n                     \"Cluster 20\",\n                     \"Cluster 25\",\n                     \"Cluster 30\",\n                     \"Cluster 35\",\n                     \"Cluster 40\",\n                     \"Name\",\n                     \"State\",\n                     \"MSA\",\n                     \"Total Population (2019)\",\n                     \"Population Change\",\n                     \"Median Age\",\n                     \"% Population in Labor Force\",\n                     \"% Population in Poverty\",\n                     \"% Population People of Color\",\n                     \"$% Population with Bachelor's Degree\",\n                     \"% Population Foreign Born\",\n                     \"Net Domestic Migration\",\n                     \"Higher Education Employment\",\n                     \"Higher Education Establishments\",\n                     \"Hospital Employment\",\n                     \"Hospital Establishments\",\n                     \"Higher Education Enrollment\",\n                     \"High Research Doctoral Degree Institutions\",\n                     \"Total Pell Grant Amounts Awarded\",\n                     \"Hospitals/Community Hospitals\",\n                     \"Hospital Beds\",\n                     \"NIH Research Funding\")\n\nwrite_csv(data.out.cor,\n          here::here(\"data/raw-data-with-cluster-ids-correlation.csv\"))\n```\n:::\n\n\n#### Visualization for Correlation Method\n\nWhat we find below is that we get more even distribution of the MSAs across clusters. However, we also tend to find some variables have clusters with a high level of variation within cluster. Some clusters are tighly grouped on the input variable of interest while others see a very large range in input variable values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.long <- data.out.cor |> \n  pivot_longer(cols = starts_with(\"Cluster\"),\n               names_to = \"Cluster Size\",\n               values_to = \"Cluster ID\") |> \n  mutate(`Cluster Size` = factor(`Cluster Size`, \n                                 levels = c(\"Cluster 5\", \n                                            \"Cluster 10\", \n                                            \"Cluster 15\", \n                                            \"Cluster 20\", \n                                            \"Cluster 25\", \n                                            \"Cluster 30\", \n                                            \"Cluster 35\", \n                                            \"Cluster 40\")))\n\n\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `% Population Foreign Born`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Correlation Method\",\n       subtitle = \"% Foreign Born\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `Higher Education Employment`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Correlation Method\",\n       subtitle = \"Higher Education Employment\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `% Population People of Color`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Correlation Method\",\n       subtitle = \"% Population People of Color\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `Hospital Establishments`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Correlation Method\",\n       subtitle = \"Hospital Establishments\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-2-4.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `NIH Research Funding`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Correlation Method\",\n       subtitle = \"NIH Research Funding\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-2-5.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `Total Pell Grant Amounts Awarded`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"Correlation Method\",\n       subtitle = \"Total Pell Grant Amounts Awarded\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-2-6.png){width=672}\n:::\n:::\n\n\n### K-Means Method\n\nK-Means is another method for calculating clusters, but it requires us to specify the exact number of clusters we want at the outset. While we play with different cluster sizes above, the hierarchical clustering method is generating a range of clusters from 1--N in size and allows us to specify different cut points along that range. Here we have to run the method 8 times to obtain the same 8 different cluster sizes/groupings.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# List of distances to use in generating clusters\ncluster.size.list <- list(\"5\" = 5, \n                          \"10\" = 10,\n                          \"15\" = 15,\n                          \"20\" = 20, \n                          \"25\" = 25, \n                          \"30\" = 30,\n                          \"35\" = 35,\n                          \"40\" = 40)\n\n# Need to run the kmeans procedure multiple times to generate clusters\ncluster.ids <- map(\n  .x = seq_along(cluster.size.list),\n  .f = ~ kmeans(data.clean,\n                centers = cluster.size.list[[.x]]) \n  )  \n\ncluster.ids.combined <- bind_cols(cluster.ids[[1]]$cluster,\n                                  cluster.ids[[2]]$cluster,\n                                  cluster.ids[[3]]$cluster,\n                                  cluster.ids[[4]]$cluster,\n                                  cluster.ids[[5]]$cluster,\n                                  cluster.ids[[6]]$cluster,\n                                  cluster.ids[[7]]$cluster,\n                                  cluster.ids[[8]]$cluster)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...4`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n```\n:::\n\n```{.r .cell-code}\nnames(cluster.ids.combined) <- c(\"Cluster 5\",\n                                 \"Cluster 10\",\n                                 \"Cluster 15\",\n                                 \"Cluster 20\",\n                                 \"Cluster 25\",\n                                 \"Cluster 30\",\n                                 \"Cluster 35\",\n                                 \"Cluster 40\")\n\n\ndata.out.kmeans <- data |> \n  bind_cols(cluster.ids.combined) |> \n  dplyr::select(starts_with(\"Cluster\"), Name, State, MSA, varlist)\n\nnames(data.out.kmeans) <- c(\"Cluster 5\",\n                     \"Cluster 10\",\n                     \"Cluster 15\",\n                     \"Cluster 20\",\n                     \"Cluster 25\",\n                     \"Cluster 30\",\n                     \"Cluster 35\",\n                     \"Cluster 40\",\n                     \"Name\",\n                     \"State\",\n                     \"MSA\",\n                     \"Total Population (2019)\",\n                     \"Population Change\",\n                     \"Median Age\",\n                     \"% Population in Labor Force\",\n                     \"% Population in Poverty\",\n                     \"% Population People of Color\",\n                     \"$% Population with Bachelor's Degree\",\n                     \"% Population Foreign Born\",\n                     \"Net Domestic Migration\",\n                     \"Higher Education Employment\",\n                     \"Higher Education Establishments\",\n                     \"Hospital Employment\",\n                     \"Hospital Establishments\",\n                     \"Higher Education Enrollment\",\n                     \"High Research Doctoral Degree Institutions\",\n                     \"Total Pell Grant Amounts Awarded\",\n                     \"Hospitals/Community Hospitals\",\n                     \"Hospital Beds\",\n                     \"NIH Research Funding\")\n\nwrite_csv(data.out.kmeans,\n          here::here(\"data/raw-data-with-cluster-ids-kmeans.csv\"))\n```\n:::\n\n\n#### K-Means Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.long <- data.out.kmeans |> \n  pivot_longer(cols = starts_with(\"Cluster\"),\n               names_to = \"Cluster Size\",\n               values_to = \"Cluster ID\") |> \n  mutate(`Cluster Size` = factor(`Cluster Size`, \n                                 levels = c(\"Cluster 5\", \n                                            \"Cluster 10\", \n                                            \"Cluster 15\", \n                                            \"Cluster 20\", \n                                            \"Cluster 25\", \n                                            \"Cluster 30\", \n                                            \"Cluster 35\", \n                                            \"Cluster 40\")))\n\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `% Population Foreign Born`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"K-Means Method\",\n       subtitle = \"% Foreign Born\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `Higher Education Employment`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"K-Means Method\",\n       subtitle = \"Higher Education Employment\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `% Population People of Color`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"K-Means Method\",\n       subtitle = \"% Population People of Color\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `Hospital Establishments`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"K-Means Method\",\n       subtitle = \"Hospital Establishments\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-3-4.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `NIH Research Funding`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"K-Means Method\",\n       subtitle = \"NIH Research Funding\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-3-5.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data = data.long) +\n  geom_point(aes(x = `Cluster ID`, y = `Total Pell Grant Amounts Awarded`)) +\n  facet_wrap(. ~ `Cluster Size`) +\n  labs(title = \"K-Means Method\",\n       subtitle = \"Total Pell Grant Amounts Awarded\")\n```\n\n::: {.cell-output-display}\n![](cluster-analysis-uno-2_files/figure-html/unnamed-chunk-3-6.png){width=672}\n:::\n:::\n",
    "supporting": [
      "cluster-analysis-uno-2_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}