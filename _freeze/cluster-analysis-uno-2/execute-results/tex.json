{
  "hash": "4308d6d3971907b72f31b1db0cb95075",
  "result": {
    "markdown": "---\ntitle: \"Exploratory Cluster Analysis for Josie Schafer: Phase II\"\nauthor: \"Michael Flynn, Prior Analytics, LLC.\"\nfontsize: \"11\"\nformat: \n  html: default\n  pdf: default\npdf-engine: pdflatex\nbibliography: references.bib\ncsl: \"CSL/apsa.csl\"\n---\n\n\n\n\n\n# Goals\n\n1.  Focus on developing and refining the clustering procedure.\n2.  Look at making the distribution of MSAs across clusters more even.\n3.  Focus on trying to develop more coherence with respect to demographics, higher education, and hospital elements of the cluster procedures. That is, make sure clusters make more sense.\n\n# Notes\n\n1.  Previously focused on hierarchical clustering\n2.  Look at K-means clustering more. This pre-specifies the number of clusters in the data.\n3.  Also possible to look at principal components analysis or factor analysis.\n4.  Revisit the distance calculation.\n\n-   Hierarchical clustering may still make sense if we're calculating the distance using alternative methods. Euclidean is the default, but other algorithms may offer better results. - Correlation based distance calculations may make more sense as we're interested in similarities along the basis of the input measures.\n-   Be aware that we're looking at the `dist()` function distance calculation and then the algorithm for calculating the clusters in `hclust()`. The former handles the distance calculation and the latter handles the breakdown into different clusters.\n-   We want to continue rescaling the measures so that certain large values from spending variables don't overwhelm the influence of other variables not on such large scales.\n\n5.  I'm going to try another rescaling procedure, but there are some definite outliers, so reverting to the 0-1 scaling may prove to be a better option still. But some spending-based measures produce large outliers and this may help to differentiate some MSAs.\n\n# Data Cleaning\n\nJust like last time we read in the data and clean it and rescale the variables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read in data and select relevant variables for clusters. \n# Focus is on demographic and anchor institution variables.\n\n# Read in raw data file\ndata <- readxl::read_xlsx(here(\"data/anchor regions analysis.xlsx\"))\n\n# List of variables to include in clustering\nvarlist <- c(\"totpop_19\",  # Total pop\n             \"popchange\",  # pop change\n             \"medage\",     # Median age\n             \"labfor\",     # percent population in labor force\n             \"pov\",       # percent population living in poverty\n             \"poc\",       # people of color as percent of pop\n             \"highed\",     # Percent population with at least bachelor's \n             \"forborn\",    # Percent population foreign born\n             \"net_mig\",    # Net domestic migration\n             \"highered_emp_qcew\", \n             \"highered_estab_qcew\",\n             \"hospital_emp_qcew\", \n             \"hospital_estab_qcew\",\n             \"inst_ipeds_enrollment_all\", \n             \"inst_ipeds_doctoralunihighrese\", \n             \"inst_ipeds_pellawards\",\n             \"inst_hosp_ahacommunityhospitals\",\n             \"inst_hosp_ahabeds\",\n             \"inst_hosp_nihresearchfunding\")\n\n# Rescale the variables from 0-1\ndata.clean <- data |>\n  mutate(across(all_of(varlist), # Variables to scale\n                ~scale(.x),                                          # Scale relative to max\n                .names = \"{col}_rescaled\")) |>                             # Add \"max\" suffix\n  dplyr::select(MSA, ends_with(\"_rescaled\")) |>                            # select chosen variables\n  column_to_rownames(\"MSA\")\n```\n:::\n\n\n\n# Clustering Methods\n\n## Hierarchical Clustering Procedure\n\nRescaling to z scores rather than scaling relative to the maximum of the category produces more evenly distributed clusters, all else being equal.\n\nI'm keeping the same number of clusters (i.e. 8 clusters with sizes ranging from 5--40, increasing in increments of 5).\n\nHowever, this time I calculate distance according to the correlation method. Resources indicate that the correlation method can be better for matching similarities across dimensions, whereas Euclidean distance is going to be better at matching on the basis of volume/spending levels, regardless of similarities across particular dimensions/variables [@JamesWittenHastieTibshirani2021].\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndistance.matrix <- as.matrix(data.clean) # convert to matrix\n\ndistance <- as.dist(1 - cor(t(distance.matrix))) # calculate correlation-based\n\nhc.tree <- hclust(distance, method = \"complete\") # Create cluster groupings based on distance\n\n\n# List of distances to use in generating clusters\ncluster.size.list <- list(\"5\" = 5, \n                          \"10\" = 10,\n                          \"15\" = 15,\n                          \"20\" = 20, \n                          \"25\" = 25, \n                          \"30\" = 30,\n                          \"35\" = 35,\n                          \"40\" = 40)\n\ncluster.ids <- map(\n  .x = seq_along(cluster.size.list),\n  .f = ~ cutree(hc.tree, k = cluster.size.list[[.x]])\n                   ) |> \n  bind_cols() \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n* `` -> `...1`\n* `` -> `...2`\n* `` -> `...3`\n* `` -> `...4`\n* `` -> `...5`\n* `` -> `...6`\n* `` -> `...7`\n* `` -> `...8`\n```\n:::\n\n```{.r .cell-code}\nnames(cluster.ids) <- c(\"cluster_5\", \"cluster_10\", \"cluster_15\", \"cluster_20\", \"cluster_25\", \"cluster_30\", \"cluster_35\", \"cluster_40\")\n\ndata.out <- data |> \n  bind_cols(cluster.ids) |> \n  dplyr::select(starts_with(\"cluster\"), Name, State, MSA, varlist)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using an external vector in selections was deprecated in tidyselect 1.1.0.\ni Please use `all_of()` or `any_of()` instead.\n  # Was:\n  data %>% select(varlist)\n\n  # Now:\n  data %>% select(all_of(varlist))\n\nSee <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\n```\n:::\n\n```{.r .cell-code}\nnames(data.out) <- c(\"Cluster 5\",\n                     \"Cluster 10\",\n                     \"Cluster 15\",\n                     \"Cluster 20\",\n                     \"Cluster 25\",\n                     \"Cluster 30\",\n                     \"Cluster 35\",\n                     \"Cluster 40\",\n                     \"Name\",\n                     \"State\",\n                     \"MSA\",\n                     \"Total Population (2019)\",\n                     \"Population Change\",\n                     \"Median Age\",\n                     \"% Population in Labor Force\",\n                     \"% Population in Poverty\",\n                     \"% Population People of Color\",\n                     \"$% Population with Bachelor's Degree\",\n                     \"% Population Foreign Born\",\n                     \"Net Domestic Migration\",\n                     \"Higher Education Employment\",\n                     \"Higher Education Establishments\",\n                     \"Hospital Employment\",\n                     \"Hospital Establishments\",\n                     \"Higher Education Enrollment\",\n                     \"High Research Doctoral Degree Institutions\",\n                     \"Total Pell Grant Amounts Awarded\",\n                     \"Hospitals/Community Hospitals\",\n                     \"Hospital Beds\",\n                     \"NIH Research Funding\")\n\nwrite_csv(data.out,\n          here::here(\"data/raw-data-with-cluster-ids-phase-2.csv\"))\n```\n:::\n",
    "supporting": [
      "cluster-analysis-uno-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{longtable}\n\\usepackage{array}\n\\usepackage{multirow}\n\\usepackage{wrapfig}\n\\usepackage{float}\n\\usepackage{colortbl}\n\\usepackage{pdflscape}\n\\usepackage{tabu}\n\\usepackage{threeparttable}\n\\usepackage{threeparttablex}\n\\usepackage[normalem]{ulem}\n\\usepackage{makecell}\n\\usepackage{xcolor}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}